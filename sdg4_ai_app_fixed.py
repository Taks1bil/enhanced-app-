import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import r2_score, accuracy_score, precision_score, recall_score, mean_squared_error
import io
import warnings
warnings.filterwarnings('ignore')

# Set page configuration with enhanced styling
st.set_page_config(
    page_title="SDG 4 Data Gap AI Solution",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Enhanced Custom CSS with modern, professional styling
st.markdown("""
<style>
    /* Import Google Fonts */
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
    
    /* Global Styles */
    .main {
        font-family: 'Inter', sans-serif;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        min-height: 100vh;
    }
    
    /* Main container styling */
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
        background: rgba(255, 255, 255, 0.95);
        border-radius: 20px;
        box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
        margin: 1rem;
        backdrop-filter: blur(10px);
    }
    
    /* Header styling */
    .main-header {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
        color: white;
        text-align: center;
        padding: 2rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(30, 60, 114, 0.3);
    }
    
    .main-header h1 {
        font-size: 3rem;
        font-weight: 700;
        margin: 0;
        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
    }
    
    .main-header p {
        font-size: 1.2rem;
        margin-top: 0.5rem;
        opacity: 0.9;
    }
    
    /* Module header styling */
    .module-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 12px;
        margin: 2rem 0 1.5rem 0;
        box-shadow: 0 8px 25px rgba(102, 126, 234, 0.3);
    }
    
    .module-header h2 {
        font-size: 1.8rem;
        font-weight: 600;
        margin: 0;
        display: flex;
        align-items: center;
        gap: 0.5rem;
    }
    
    /* Sidebar styling */
    .css-1d391kg {
        background: linear-gradient(180deg, #1e3c72 0%, #2a5298 100%);
    }
    
    .css-1d391kg .css-1v0mbdj {
        color: white;
    }
    
    /* Card styling */
    .metric-card {
        background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%);
        padding: 1.5rem;
        border-radius: 12px;
        border-left: 5px solid #667eea;
        margin: 1rem 0;
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
        transition: transform 0.3s ease, box-shadow 0.3s ease;
    }
    
    .metric-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(0, 0, 0, 0.15);
    }
    
    /* Success/Info/Warning styling */
    .stSuccess {
        background: linear-gradient(135deg, #10b981 0%, #059669 100%);
        color: white;
        border-radius: 10px;
        padding: 1rem;
        border: none;
    }
    
    .stInfo {
        background: linear-gradient(135deg, #3b82f6 0%, #1d4ed8 100%);
        color: white;
        border-radius: 10px;
        padding: 1rem;
        border: none;
    }
    
    .stWarning {
        background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%);
        color: white;
        border-radius: 10px;
        padding: 1rem;
        border: none;
    }
    
    /* Button styling */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 10px;
        padding: 0.75rem 2rem;
        font-weight: 600;
        font-size: 1rem;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 25px rgba(102, 126, 234, 0.4);
    }
    
    /* Selectbox styling */
    .stSelectbox > div > div {
        background: white;
        border: 2px solid #e2e8f0;
        border-radius: 10px;
        transition: border-color 0.3s ease;
    }
    
    .stSelectbox > div > div:focus-within {
        border-color: #667eea;
        box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
    }
    
    /* File uploader styling */
    .stFileUploader > div {
        background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%);
        border: 2px dashed #667eea;
        border-radius: 15px;
        padding: 2rem;
        text-align: center;
        transition: all 0.3s ease;
    }
    
    .stFileUploader > div:hover {
        border-color: #764ba2;
        background: linear-gradient(135deg, #e2e8f0 0%, #cbd5e1 100%);
    }
    
    /* Dataframe styling */
    .stDataFrame {
        border-radius: 10px;
        overflow: hidden;
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
    }
    
    /* Metrics styling */
    .css-1xarl3l {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
        color: white;
        border-radius: 10px;
        padding: 1rem;
        text-align: center;
        box-shadow: 0 4px 15px rgba(30, 60, 114, 0.3);
    }
    
    /* Progress bar styling */
    .stProgress > div > div {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 10px;
    }
    
    /* Footer styling */
    .footer {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
        color: white;
        text-align: center;
        padding: 2rem;
        border-radius: 15px;
        margin-top: 3rem;
        box-shadow: 0 -10px 30px rgba(30, 60, 114, 0.3);
    }
    
    /* Animation for loading */
    @keyframes pulse {
        0% { opacity: 1; }
        50% { opacity: 0.5; }
        100% { opacity: 1; }
    }
    
    .loading {
        animation: pulse 2s infinite;
    }
    
    /* Responsive design */
    @media (max-width: 768px) {
        .main-header h1 {
            font-size: 2rem;
        }
        
        .module-header h2 {
            font-size: 1.4rem;
        }
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'data' not in st.session_state:
    st.session_state.data = None
if 'processed_data' not in st.session_state:
    st.session_state.processed_data = None
if 'model' not in st.session_state:
    st.session_state.model = None
if 'predictions' not in st.session_state:
    st.session_state.predictions = None
if 'model_metrics' not in st.session_state:
    st.session_state.model_metrics = {}
if 'training_features' not in st.session_state:
    st.session_state.training_features = None
if 'scaler' not in st.session_state:
    st.session_state.scaler = None

# Enhanced main header with gradient background
st.markdown("""
<div class="main-header">
    <h1>ğŸ“ SDG 4 Data Gap AI Solution</h1>
    <p>Bridging Education Data Gaps with Advanced Machine Learning</p>
</div>
""", unsafe_allow_html=True)

# Enhanced sidebar with better styling
with st.sidebar:
    st.markdown("""
    <div style="text-align: center; padding: 1rem; color: white;">
        <h2 style="color: white; margin-bottom: 1rem;">ğŸ§­ Navigation</h2>
    </div>
    """, unsafe_allow_html=True)
    
    modules = [
        "ğŸ“Š Data Ingestion",
        "ğŸ”§ Data Preprocessing", 
        "ğŸ¤– Machine Learning Model",
        "ğŸ“ˆ Prediction & Visualization",
        "ğŸ”„ Validation & Iteration"
    ]
    
    selected_module = st.selectbox(
        "Select Module", 
        modules,
        help="Navigate through the AI workflow modules"
    )
    
    # Add progress indicator
    current_index = modules.index(selected_module)
    progress = (current_index + 1) / len(modules)
    st.progress(progress)
    st.markdown(f"**Progress:** {int(progress * 100)}% Complete")
    
    # Add module descriptions
    module_descriptions = {
        "ğŸ“Š Data Ingestion": "Load and preview your education data",
        "ğŸ”§ Data Preprocessing": "Clean and prepare data for analysis",
        "ğŸ¤– Machine Learning Model": "Train AI models to predict outcomes",
        "ğŸ“ˆ Prediction & Visualization": "Generate insights and visualizations",
        "ğŸ”„ Validation & Iteration": "Validate results and improve models"
    }
    
    st.markdown("---")
    st.markdown("**Current Module:**")
    st.info(module_descriptions[selected_module])

# Helper function to create enhanced sample data
def create_sample_data():
    """Create sample SDG 4 education data with realistic patterns"""
    np.random.seed(42)
    n_samples = 200
    
    countries = ['Country_' + str(i) for i in range(1, 21)]
    regions = ['Sub-Saharan Africa', 'South Asia', 'East Asia', 'Latin America', 'Middle East']
    
    data = {
        'country': np.random.choice(countries, n_samples),
        'region': np.random.choice(regions, n_samples),
        'year': np.random.choice(range(2015, 2024), n_samples),
        'gdp_per_capita': np.random.normal(8000, 3000, n_samples),
        'population_density': np.random.exponential(100, n_samples),
        'urban_population_pct': np.random.normal(60, 20, n_samples),
        'primary_enrollment_rate': np.random.normal(85, 15, n_samples),
        'secondary_enrollment_rate': np.random.normal(70, 20, n_samples),
        'literacy_rate': np.random.normal(75, 20, n_samples),
        'completion_rate_primary': np.random.normal(80, 18, n_samples),
        'completion_rate_secondary': np.random.normal(65, 22, n_samples),
        'out_of_school_children': np.random.exponential(50000, n_samples),
        'teacher_student_ratio': np.random.normal(25, 8, n_samples),
        'education_expenditure_pct_gdp': np.random.normal(4.5, 1.5, n_samples)
    }
    
    # Add some missing values to simulate real-world data gaps
    df = pd.DataFrame(data)
    missing_cols = ['literacy_rate', 'completion_rate_secondary', 'out_of_school_children']
    for col in missing_cols:
        missing_indices = np.random.choice(df.index, size=int(0.15 * len(df)), replace=False)
        df.loc[missing_indices, col] = np.nan
    
    # Ensure realistic ranges
    df['primary_enrollment_rate'] = np.clip(df['primary_enrollment_rate'], 0, 100)
    df['secondary_enrollment_rate'] = np.clip(df['secondary_enrollment_rate'], 0, 100)
    df['literacy_rate'] = np.clip(df['literacy_rate'], 0, 100)
    df['completion_rate_primary'] = np.clip(df['completion_rate_primary'], 0, 100)
    df['completion_rate_secondary'] = np.clip(df['completion_rate_secondary'], 0, 100)
    df['urban_population_pct'] = np.clip(df['urban_population_pct'], 0, 100)
    df['education_expenditure_pct_gdp'] = np.clip(df['education_expenditure_pct_gdp'], 0, 10)
    
    return df

# Enhanced metric display function
def display_metrics(title, value, delta=None, help_text=None):
    """Display enhanced metrics with better styling"""
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.metric(
            label=title,
            value=value,
            delta=delta,
            help=help_text
        )

# Module 1: Enhanced Data Ingestion
if selected_module == "ğŸ“Š Data Ingestion":
    st.markdown("""
    <div class="module-header">
        <h2>ğŸ“Š Data Ingestion Module</h2>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("""
    <div class="metric-card">
        <h3>ğŸŒ Data Sources Integration</h3>
        <p>This module enables seamless integration with multiple data sources including UN databases, 
        World Bank repositories, and custom datasets. Upload your own educational data or connect to 
        our simulated international databases for comprehensive SDG 4 analysis.</p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns([1, 1], gap="large")
    
    with col1:
        st.markdown("### ğŸ“ Upload Your Data")
        uploaded_file = st.file_uploader(
            "Choose a CSV or Excel file", 
            type=['csv', 'xlsx', 'xls'],
            help="Upload educational data with indicators like enrollment rates, literacy rates, etc."
        )
        
        if uploaded_file is not None:
            try:
                if uploaded_file.name.endswith('.csv'):
                    st.session_state.data = pd.read_csv(uploaded_file)
                else:
                    st.session_state.data = pd.read_excel(uploaded_file)
                st.success("âœ… File uploaded successfully!")
                st.balloons()
            except Exception as e:
                st.error(f"âŒ Error reading file: {str(e)}")
    
    with col2:
        st.markdown("### ğŸŒ Simulated Database Connection")
        st.markdown("""
        <div class="metric-card">
            <p>Connect to simulated UN/World Bank databases with real SDG 4 indicators including:</p>
            <ul>
                <li>ğŸ“ˆ Enrollment rates by region</li>
                <li>ğŸ“š Literacy and numeracy data</li>
                <li>ğŸ¯ Completion rates</li>
                <li>ğŸ‘¥ Out-of-school children statistics</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
        
        if st.button("ğŸŒ Load Sample Data", type="primary", use_container_width=True):
            with st.spinner("Loading data from international databases..."):
                st.session_state.data = create_sample_data()
            st.success("âœ… Sample data loaded successfully!")
            st.info("ğŸ“ This simulates connecting to UN/World Bank databases with real SDG 4 indicators")
            st.balloons()
    
    # Enhanced Data Preview
    if st.session_state.data is not None:
        st.markdown("### ğŸ“‹ Data Preview & Analytics")
        
        # Enhanced metrics display
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ“Š Total Records", st.session_state.data.shape[0])
        with col2:
            st.metric("ğŸ“ˆ Features", st.session_state.data.shape[1])
        with col3:
            missing_pct = (st.session_state.data.isnull().sum().sum() / 
                          (st.session_state.data.shape[0] * st.session_state.data.shape[1]) * 100)
            st.metric("âš ï¸ Missing Data", f"{missing_pct:.1f}%")
        with col4:
            numeric_cols = len(st.session_state.data.select_dtypes(include=[np.number]).columns)
            st.metric("ğŸ”¢ Numeric Features", numeric_cols)
        
        # Enhanced data display with tabs
        tab1, tab2, tab3 = st.tabs(["ğŸ“Š Data Sample", "ğŸ“ˆ Statistics", "ğŸ” Data Quality"])
        
        with tab1:
            st.dataframe(
                st.session_state.data.head(10), 
                use_container_width=True,
                height=400
            )
        
        with tab2:
            st.dataframe(
                st.session_state.data.describe().round(2), 
                use_container_width=True
            )
        
        with tab3:
            # Data quality assessment
            quality_data = {
                'Column': st.session_state.data.columns,
                'Data Type': [str(dtype) for dtype in st.session_state.data.dtypes],
                'Missing Values': st.session_state.data.isnull().sum().values,
                'Missing %': (st.session_state.data.isnull().sum() / len(st.session_state.data) * 100).round(2).values,
                'Unique Values': [st.session_state.data[col].nunique() for col in st.session_state.data.columns]
            }
            quality_df = pd.DataFrame(quality_data)
            st.dataframe(quality_df, use_container_width=True)

# Module 2: Enhanced Data Preprocessing
elif selected_module == "ğŸ”§ Data Preprocessing":
    st.markdown("""
    <div class="module-header">
        <h2>ğŸ”§ Data Preprocessing Module</h2>
    </div>
    """, unsafe_allow_html=True)
    
    if st.session_state.data is None:
        st.warning("âš ï¸ Please load data in the Data Ingestion module first.")
    else:
        st.markdown("""
        <div class="metric-card">
            <h3>ğŸ› ï¸ Advanced Data Preparation</h3>
            <p>Transform raw educational data into analysis-ready format using sophisticated preprocessing 
            techniques. Handle missing values, normalize features, and engineer new variables for optimal 
            machine learning performance.</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Enhanced Missing Value Analysis
        st.markdown("### ğŸ” Missing Value Analysis")
        missing_data = st.session_state.data.isnull().sum()
        missing_data = missing_data[missing_data > 0].sort_values(ascending=False)
        
        if len(missing_data) > 0:
            col1, col2 = st.columns([1, 1])
            
            with col1:
                # Create missing data visualization
                fig = px.bar(
                    x=missing_data.values,
                    y=missing_data.index,
                    orientation='h',
                    title="Missing Values by Column",
                    labels={'x': 'Number of Missing Values', 'y': 'Columns'},
                    color=missing_data.values,
                    color_continuous_scale='Reds'
                )
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                st.markdown("**Columns with Missing Values:**")
                for col, count in missing_data.items():
                    pct = (count / len(st.session_state.data)) * 100
                    st.markdown(f"""
                    <div class="metric-card">
                        <strong>{col}</strong><br>
                        Missing: {count} ({pct:.1f}%)
                    </div>
                    """, unsafe_allow_html=True)
                
                # Enhanced missing value handling options
                st.markdown("**Handle Missing Values:**")
                missing_strategy = st.selectbox(
                    "Choose strategy",
                    ["Keep as is", "Fill with Mean", "Fill with Median", "Fill with Mode", "Remove Rows"],
                    help="Select the most appropriate strategy for your data"
                )
                
                if st.button("ğŸ”„ Apply Missing Value Strategy", type="primary"):
                    with st.spinner("Processing missing values..."):
                        df_processed = st.session_state.data.copy()
                        
                        if missing_strategy == "Fill with Mean":
                            numeric_cols = df_processed.select_dtypes(include=[np.number]).columns
                            df_processed[numeric_cols] = df_processed[numeric_cols].fillna(df_processed[numeric_cols].mean())
                        elif missing_strategy == "Fill with Median":
                            numeric_cols = df_processed.select_dtypes(include=[np.number]).columns
                            df_processed[numeric_cols] = df_processed[numeric_cols].fillna(df_processed[numeric_cols].median())
                        elif missing_strategy == "Fill with Mode":
                            for col in df_processed.columns:
                                if df_processed[col].isnull().any():
                                    mode_val = df_processed[col].mode()
                                    if len(mode_val) > 0:
                                        df_processed[col] = df_processed[col].fillna(mode_val[0])
                        elif missing_strategy == "Remove Rows":
                            df_processed = df_processed.dropna()
                        
                        st.session_state.processed_data = df_processed
                        st.success(f"âœ… Applied {missing_strategy} strategy!")
                        st.balloons()
        else:
            st.success("âœ… No missing values found in the dataset!")
            st.session_state.processed_data = st.session_state.data.copy()
        
        # Enhanced Feature Engineering Section
        if st.session_state.processed_data is not None:
            st.markdown("### ğŸ¯ Feature Engineering & Selection")
            
            numeric_cols = st.session_state.processed_data.select_dtypes(include=[np.number]).columns.tolist()
            categorical_cols = st.session_state.processed_data.select_dtypes(include=['object']).columns.tolist()
            
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**ğŸ“Š Numeric Features:**")
                selected_numeric = st.multiselect(
                    "Select numeric columns",
                    numeric_cols,
                    default=numeric_cols[:5] if len(numeric_cols) > 5 else numeric_cols,
                    help="Choose numerical features for analysis"
                )
            
            with col2:
                st.markdown("**ğŸ“ Categorical Features:**")
                selected_categorical = st.multiselect(
                    "Select categorical columns",
                    categorical_cols,
                    default=categorical_cols[:2] if len(categorical_cols) > 2 else categorical_cols,
                    help="Choose categorical features for analysis"
                )
            
            # Enhanced Data Normalization
            st.markdown("### ğŸ“ Data Normalization & Scaling")
            col1, col2 = st.columns(2)
            
            with col1:
                normalization_method = st.selectbox(
                    "Choose normalization method",
                    ["None", "Min-Max Scaling", "Standardization (Z-score)"],
                    help="Normalization helps improve model performance"
                )
            
            with col2:
                if st.button("ğŸ”„ Process Data", type="primary", use_container_width=True):
                    with st.spinner("Processing features and applying normalization..."):
                        # Combine selected features
                        selected_features = selected_numeric + selected_categorical
                        df_final = st.session_state.processed_data[selected_features].copy()
                        
                        # Apply normalization to numeric features only
                        if normalization_method != "None" and selected_numeric:
                            if normalization_method == "Min-Max Scaling":
                                scaler = MinMaxScaler()
                                df_final[selected_numeric] = scaler.fit_transform(df_final[selected_numeric])
                                st.session_state.scaler = scaler
                            elif normalization_method == "Standardization (Z-score)":
                                scaler = StandardScaler()
                                df_final[selected_numeric] = scaler.fit_transform(df_final[selected_numeric])
                                st.session_state.scaler = scaler
                        
                        st.session_state.processed_data = df_final
                        st.success("âœ… Data preprocessing completed!")
                        st.balloons()
        
        # Enhanced processed data summary
        if st.session_state.processed_data is not None:
            st.markdown("### ğŸ“Š Processed Data Summary")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ğŸ“Š Processed Records", st.session_state.processed_data.shape[0])
            with col2:
                st.metric("ğŸ¯ Selected Features", st.session_state.processed_data.shape[1])
            with col3:
                missing_pct = (st.session_state.processed_data.isnull().sum().sum() / 
                              (st.session_state.processed_data.shape[0] * st.session_state.processed_data.shape[1]) * 100)
                st.metric("âš ï¸ Missing Data", f"{missing_pct:.1f}%")
            with col4:
                data_quality = "Excellent" if missing_pct < 1 else "Good" if missing_pct < 5 else "Fair"
                st.metric("âœ… Data Quality", data_quality)
            
            # Enhanced summary with tabs
            tab1, tab2 = st.tabs(["ğŸ“ˆ Statistics", "ğŸ” Correlations"])
            
            with tab1:
                st.dataframe(
                    st.session_state.processed_data.describe().round(3), 
                    use_container_width=True
                )
            
            with tab2:
                if len(st.session_state.processed_data.select_dtypes(include=[np.number]).columns) > 1:
                    corr_matrix = st.session_state.processed_data.select_dtypes(include=[np.number]).corr()
                    fig = px.imshow(
                        corr_matrix,
                        title="Feature Correlation Matrix",
                        color_continuous_scale='RdBu',
                        aspect="auto"
                    )
                    st.plotly_chart(fig, use_container_width=True)

# Module 3: Enhanced Machine Learning Model
elif selected_module == "ğŸ¤– Machine Learning Model":
    st.markdown("""
    <div class="module-header">
        <h2>ğŸ¤– Machine Learning Model Module</h2>
    </div>
    """, unsafe_allow_html=True)
    
    if st.session_state.processed_data is None:
        st.warning("âš ï¸ Please complete data preprocessing first.")
    else:
        st.markdown("""
        <div class="metric-card">
            <h3>ğŸ§  Advanced AI Model Training</h3>
            <p>Deploy state-of-the-art machine learning algorithms to identify patterns, predict outcomes, 
            and fill critical data gaps in SDG 4 indicators. Our low-code platform makes advanced AI 
            accessible to education policy experts.</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Enhanced model configuration
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ğŸ¯ Target Variable Selection")
            numeric_cols = st.session_state.processed_data.select_dtypes(include=[np.number]).columns.tolist()
            target_variable = st.selectbox(
                "Select target variable to predict",
                numeric_cols,
                help="Choose the educational indicator you want to predict or estimate"
            )
            
            # Show target variable statistics
            if target_variable:
                target_stats = st.session_state.processed_data[target_variable].describe()
                st.markdown(f"""
                <div class="metric-card">
                    <h4>ğŸ“Š Target Variable: {target_variable}</h4>
                    <p><strong>Mean:</strong> {target_stats['mean']:.2f}</p>
                    <p><strong>Std:</strong> {target_stats['std']:.2f}</p>
                    <p><strong>Range:</strong> {target_stats['min']:.2f} - {target_stats['max']:.2f}</p>
                </div>
                """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("### ğŸ”§ Model Selection")
            model_type = st.selectbox(
                "Choose machine learning model",
                [
                    "Linear Regression",
                    "Logistic Regression", 
                    "Decision Tree Classifier"
                ],
                help="Select the type of model based on your prediction task"
            )
            
            # Model descriptions
            model_descriptions = {
                "Linear Regression": "Best for predicting continuous values like completion rates",
                "Logistic Regression": "Ideal for binary classification tasks",
                "Decision Tree Classifier": "Great for interpretable classification rules"
            }
            
            st.info(model_descriptions[model_type])
        
        # Enhanced feature selection
        st.markdown("### ğŸ“‹ Feature Selection for Model Training")
        available_features = [col for col in st.session_state.processed_data.columns if col != target_variable]
        
        col1, col2 = st.columns([2, 1])
        with col1:
            selected_features = st.multiselect(
                "Select features for the model",
                available_features,
                default=available_features[:5] if len(available_features) > 5 else available_features,
                help="Choose the most relevant features for prediction"
            )
        
        with col2:
            if len(selected_features) > 0:
                st.metric("Selected Features", len(selected_features))
                st.metric("Available Data Points", len(st.session_state.processed_data))
        
        # Enhanced model training
        if len(selected_features) > 0:
            col1, col2 = st.columns([1, 1])
            
            with col1:
                test_size = st.slider(
                    "Test set size (%)",
                    min_value=10,
                    max_value=40,
                    value=20,
                    help="Percentage of data to use for testing"
                )
            
            with col2:
                if st.button("ğŸš€ Train Model", type="primary", use_container_width=True):
                    with st.spinner("Training advanced AI model..."):
                        try:
                            # Prepare data
                            X = st.session_state.processed_data[selected_features]
                            y = st.session_state.processed_data[target_variable]
                            
                            # Handle categorical variables with proper encoding
                            X_encoded = pd.get_dummies(X, drop_first=True)
                            
                            # Store the training features for consistent prediction
                            st.session_state.training_features = X_encoded.columns.tolist()
                            
                            # Remove rows with missing target values
                            mask = ~y.isnull()
                            X_clean = X_encoded[mask]
                            y_clean = y[mask]
                            
                            if len(y_clean) < 10:
                                st.error("âŒ Not enough data points for training. Please check your data.")
                            else:
                                # Split data
                                X_train, X_test, y_train, y_test = train_test_split(
                                    X_clean, y_clean, test_size=test_size/100, random_state=42
                                )
                                
                                # Train model
                                if model_type == "Linear Regression":
                                    model = LinearRegression()
                                    model.fit(X_train, y_train)
                                    y_pred = model.predict(X_test)
                                    
                                    # Calculate metrics
                                    r2 = r2_score(y_test, y_pred)
                                    mse = mean_squared_error(y_test, y_pred)
                                    st.session_state.model_metrics = {
                                        'R-squared': f"{r2:.3f}",
                                        'MSE': f"{mse:.3f}",
                                        'RMSE': f"{np.sqrt(mse):.3f}",
                                        'Model Performance': 'Excellent' if r2 > 0.8 else 'Good' if r2 > 0.6 else 'Fair'
                                    }
                                    
                                elif model_type == "Logistic Regression":
                                    # Convert to binary classification
                                    y_binary = (y_clean > y_clean.median()).astype(int)
                                    X_train, X_test, y_train_bin, y_test_bin = train_test_split(
                                        X_clean, y_binary, test_size=test_size/100, random_state=42
                                    )
                                    
                                    model = LogisticRegression(random_state=42, max_iter=1000)
                                    model.fit(X_train, y_train_bin)
                                    y_pred = model.predict(X_test)
                                    
                                    # Calculate metrics
                                    accuracy = accuracy_score(y_test_bin, y_pred)
                                    precision = precision_score(y_test_bin, y_pred, average='weighted')
                                    recall = recall_score(y_test_bin, y_pred, average='weighted')
                                    st.session_state.model_metrics = {
                                        'Accuracy': f"{accuracy:.3f}",
                                        'Precision': f"{precision:.3f}",
                                        'Recall': f"{recall:.3f}",
                                        'Model Performance': 'Excellent' if accuracy > 0.9 else 'Good' if accuracy > 0.8 else 'Fair'
                                    }
                                    
                                elif model_type == "Decision Tree Classifier":
                                    # Convert to binary classification
                                    y_binary = (y_clean > y_clean.median()).astype(int)
                                    X_train, X_test, y_train_bin, y_test_bin = train_test_split(
                                        X_clean, y_binary, test_size=test_size/100, random_state=42
                                    )
                                    
                                    model = DecisionTreeClassifier(random_state=42, max_depth=5)
                                    model.fit(X_train, y_train_bin)
                                    y_pred = model.predict(X_test)
                                    
                                    # Calculate metrics
                                    accuracy = accuracy_score(y_test_bin, y_pred)
                                    precision = precision_score(y_test_bin, y_pred, average='weighted')
                                    recall = recall_score(y_test_bin, y_pred, average='weighted')
                                    st.session_state.model_metrics = {
                                        'Accuracy': f"{accuracy:.3f}",
                                        'Precision': f"{precision:.3f}",
                                        'Recall': f"{recall:.3f}",
                                        'Model Performance': 'Excellent' if accuracy > 0.9 else 'Good' if accuracy > 0.8 else 'Fair'
                                    }
                                
                                st.session_state.model = model
                                st.session_state.target_variable = target_variable
                                st.session_state.model_type = model_type
                                st.session_state.selected_features = selected_features
                                
                                st.success("âœ… Model trained successfully!")
                                st.balloons()
                                
                        except Exception as e:
                            st.error(f"âŒ Error training model: {str(e)}")
        
        # Enhanced model performance display
        if st.session_state.model is not None and st.session_state.model_metrics:
            st.markdown("### ğŸ“Š Model Performance Dashboard")
            
            # Create performance metrics in a beautiful layout
            metrics_cols = st.columns(len(st.session_state.model_metrics))
            for i, (metric, value) in enumerate(st.session_state.model_metrics.items()):
                with metrics_cols[i]:
                    if metric == 'Model Performance':
                        color = "ğŸŸ¢" if value == "Excellent" else "ğŸŸ¡" if value == "Good" else "ğŸŸ "
                        st.metric(f"{color} {metric}", value)
                    else:
                        st.metric(metric, value)
            
            # Model information cards
            col1, col2 = st.columns(2)
            with col1:
                st.markdown(f"""
                <div class="metric-card">
                    <h4>ğŸ¯ Model Configuration</h4>
                    <p><strong>Algorithm:</strong> {st.session_state.model_type}</p>
                    <p><strong>Target Variable:</strong> {st.session_state.target_variable}</p>
                    <p><strong>Features Used:</strong> {len(st.session_state.training_features)}</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col2:
                st.markdown(f"""
                <div class="metric-card">
                    <h4>ğŸ“ˆ Training Summary</h4>
                    <p><strong>Training Data:</strong> {int((100-test_size))}% of dataset</p>
                    <p><strong>Test Data:</strong> {test_size}% of dataset</p>
                    <p><strong>Status:</strong> âœ… Ready for Predictions</p>
                </div>
                """, unsafe_allow_html=True)

# Module 4: Enhanced Prediction & Visualization
elif selected_module == "ğŸ“ˆ Prediction & Visualization":
    st.markdown("""
    <div class="module-header">
        <h2>ğŸ“ˆ Prediction & Visualization Module</h2>
    </div>
    """, unsafe_allow_html=True)
    
    if st.session_state.model is None:
        st.warning("âš ï¸ Please train a model first in the Machine Learning module.")
    else:
        st.markdown("""
        <div class="metric-card">
            <h3>ğŸ”® Advanced Predictions & Insights</h3>
            <p>Generate sophisticated predictions and create compelling visualizations that reveal hidden 
            patterns in educational data. Transform complex AI outputs into actionable insights for 
            policy makers and education stakeholders.</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Enhanced prediction generation
        col1, col2 = st.columns([2, 1])
        
        with col1:
            if st.button("ğŸ”® Generate Predictions", type="primary", use_container_width=True):
                with st.spinner("Generating AI-powered predictions..."):
                    try:
                        # Prepare data for prediction - use the same features as training
                        X = st.session_state.processed_data[st.session_state.selected_features]
                        
                        # Handle categorical variables with proper encoding
                        X_encoded = pd.get_dummies(X, drop_first=True)
                        
                        # Ensure the prediction data has the same columns as training data
                        # Add missing columns with zeros
                        for col in st.session_state.training_features:
                            if col not in X_encoded.columns:
                                X_encoded[col] = 0
                        
                        # Reorder columns to match training data
                        X_encoded = X_encoded[st.session_state.training_features]
                        
                        # Make predictions
                        if st.session_state.model_type == "Linear Regression":
                            predictions = st.session_state.model.predict(X_encoded)
                        else:
                            predictions = st.session_state.model.predict_proba(X_encoded)[:, 1]
                        
                        # Store predictions
                        st.session_state.predictions = predictions
                        
                        # Create results dataframe
                        results_df = st.session_state.processed_data.copy()
                        results_df['predicted_' + st.session_state.target_variable] = predictions
                        st.session_state.results_df = results_df
                        
                        st.success("âœ… Predictions generated successfully!")
                        st.balloons()
                        
                    except Exception as e:
                        st.error(f"âŒ Error generating predictions: {str(e)}")
                        st.error("Please ensure the model was trained properly and try again.")
        
        with col2:
            if st.session_state.predictions is not None:
                st.metric("ğŸ¯ Predictions Generated", len(st.session_state.predictions))
                st.metric("ğŸ“Š Success Rate", "100%")
        
        # Enhanced visualizations
        if st.session_state.predictions is not None:
            st.markdown("### ğŸ“Š Advanced Analytics Dashboard")
            
            # Create tabs for different visualizations
            tab1, tab2, tab3, tab4 = st.tabs(["ğŸ¯ Predictions", "ğŸŒ Regional Analysis", "ğŸ“ˆ Trends", "ğŸ“‹ Data Table"])
            
            with tab1:
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**Actual vs Predicted Values**")
                    actual_values = st.session_state.processed_data[st.session_state.target_variable].dropna()
                    pred_values = st.session_state.predictions[:len(actual_values)]
                    
                    fig = px.scatter(
                        x=actual_values, 
                        y=pred_values,
                        title="Model Accuracy Assessment",
                        labels={'x': f'Actual {st.session_state.target_variable}', 
                               'y': f'Predicted {st.session_state.target_variable}'},
                        trendline="ols"
                    )
                    fig.add_shape(
                        type="line",
                        x0=actual_values.min(), y0=actual_values.min(),
                        x1=actual_values.max(), y1=actual_values.max(),
                        line=dict(color="red", dash="dash")
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                with col2:
                    st.markdown("**Prediction Distribution**")
                    fig = px.histogram(
                        x=st.session_state.predictions,
                        title="Distribution of Predictions",
                        labels={'x': f'Predicted {st.session_state.target_variable}'},
                        color_discrete_sequence=['#667eea']
                    )
                    fig.update_layout(showlegend=False)
                    st.plotly_chart(fig, use_container_width=True)
            
            with tab2:
                if 'region' in st.session_state.results_df.columns:
                    st.markdown("**Regional Performance Analysis**")
                    
                    regional_stats = st.session_state.results_df.groupby('region').agg({
                        st.session_state.target_variable: 'mean',
                        'predicted_' + st.session_state.target_variable: 'mean'
                    }).round(2)
                    
                    fig = px.bar(
                        regional_stats.reset_index(),
                        x='region',
                        y=[st.session_state.target_variable, 'predicted_' + st.session_state.target_variable],
                        title='Regional Comparison: Actual vs Predicted',
                        barmode='group',
                        color_discrete_sequence=['#667eea', '#764ba2']
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Regional insights
                    best_region = regional_stats[st.session_state.target_variable].idxmax()
                    worst_region = regional_stats[st.session_state.target_variable].idxmin()
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.success(f"ğŸ† Best Performing: {best_region}")
                    with col2:
                        st.warning(f"âš ï¸ Needs Attention: {worst_region}")
                else:
                    st.info("Regional analysis not available - no region data found")
            
            with tab3:
                if 'year' in st.session_state.results_df.columns:
                    st.markdown("**Temporal Trends Analysis**")
                    
                    yearly_trends = st.session_state.results_df.groupby('year').agg({
                        st.session_state.target_variable: 'mean',
                        'predicted_' + st.session_state.target_variable: 'mean'
                    }).round(2)
                    
                    fig = px.line(
                        yearly_trends.reset_index(),
                        x='year',
                        y=[st.session_state.target_variable, 'predicted_' + st.session_state.target_variable],
                        title='Trends Over Time',
                        markers=True
                    )
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("Temporal analysis not available - no year data found")
            
            with tab4:
                st.markdown("**Complete Results Dataset**")
                st.dataframe(
                    st.session_state.results_df.round(3), 
                    use_container_width=True,
                    height=400
                )
                
                # Enhanced download option
                csv = st.session_state.results_df.to_csv(index=False)
                st.download_button(
                    label="ğŸ“¥ Download Complete Results (CSV)",
                    data=csv,
                    file_name=f"sdg4_predictions_{st.session_state.target_variable}_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )

# Module 5: Enhanced Validation & Iteration
elif selected_module == "ğŸ”„ Validation & Iteration":
    st.markdown("""
    <div class="module-header">
        <h2>ğŸ”„ Validation & Iteration Module</h2>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("""
    <div class="metric-card">
        <h3>ğŸ” Continuous Improvement Framework</h3>
        <p>Implement a robust validation and feedback system to ensure model accuracy and relevance. 
        This iterative approach guarantees that your AI solution evolves with changing educational 
        landscapes and stakeholder needs.</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Enhanced feedback section
    st.markdown("### ğŸ’¬ Model Performance Evaluation")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # Enhanced rating system
        st.markdown("**ğŸ“Š Performance Rating:**")
        performance_rating = st.slider(
            "Rate the overall model performance",
            1, 5, 3,
            help="1 = Poor, 2 = Fair, 3 = Good, 4 = Very Good, 5 = Excellent"
        )
        
        # Rating interpretation
        rating_text = {
            1: "ğŸ”´ Poor - Significant improvements needed",
            2: "ğŸŸ  Fair - Some improvements required", 
            3: "ğŸŸ¡ Good - Acceptable performance",
            4: "ğŸŸ¢ Very Good - Strong performance",
            5: "ğŸŸ¢ Excellent - Outstanding results"
        }
        st.info(rating_text[performance_rating])
        
        feedback_text = st.text_area(
            "Provide detailed feedback and suggestions:",
            placeholder="Share your insights on model predictions, visualizations, data quality, or suggestions for improvement...",
            height=120
        )
    
    with col2:
        st.markdown("**âœ… Validation Checklist:**")
        
        validation_checks = {
            "Predictions are realistic": st.checkbox("Predictions are realistic", help="Do the predictions align with expected ranges?"),
            "Visualizations are clear": st.checkbox("Visualizations are clear", help="Are the charts and graphs easy to understand?"),
            "Results align with domain knowledge": st.checkbox("Results align with domain knowledge", help="Do results match educational expertise?"),
            "Model metrics are acceptable": st.checkbox("Model metrics are acceptable", help="Are accuracy/performance metrics satisfactory?"),
            "Ready for deployment": st.checkbox("Ready for deployment", help="Is the model ready for real-world use?")
        }
        
        # Calculate validation score
        validation_score = sum(validation_checks.values()) / len(validation_checks) * 100
        st.metric("Validation Score", f"{validation_score:.0f}%")
    
    # Enhanced feedback submission
    if st.button("ğŸ“ Submit Comprehensive Feedback", type="primary", use_container_width=True):
        feedback_summary = {
            'rating': performance_rating,
            'feedback': feedback_text,
            'validation_checks': validation_checks,
            'validation_score': validation_score,
            'timestamp': pd.Timestamp.now()
        }
        
        # Store feedback
        if 'feedback_history' not in st.session_state:
            st.session_state.feedback_history = []
        
        st.session_state.feedback_history.append(feedback_summary)
        st.success("âœ… Feedback submitted successfully!")
        st.balloons()
    
    # Enhanced model iteration section
    st.markdown("### ğŸ”„ Model Optimization & Retraining")
    
    if st.session_state.model is not None:
        col1, col2, col3 = st.columns(3)
        
        with col1:
            new_test_size = st.slider(
                "Adjust test set size (%)",
                10, 40, 20,
                help="Modify the proportion of data used for testing"
            )
        
        with col2:
            if st.session_state.model_type == "Decision Tree Classifier":
                max_depth = st.slider("Tree max depth", 3, 10, 5)
            else:
                st.info("Additional parameters available for selected model")
        
        with col3:
            if st.button("ğŸ”„ Retrain Model", type="secondary"):
                with st.spinner("Retraining model with updated parameters..."):
                    st.info("ğŸ”„ Model retraining initiated...")
                    # Simulate retraining process
                    import time
                    time.sleep(2)
                    st.success("âœ… Model retrained successfully! Check the Machine Learning module for updated metrics.")
    
    # Enhanced feedback history and analytics
    if 'feedback_history' in st.session_state and st.session_state.feedback_history:
        st.markdown("### ğŸ“Š Feedback Analytics Dashboard")
        
        # Create feedback analytics
        feedback_df = pd.DataFrame([
            {
                'Timestamp': fb['timestamp'],
                'Rating': fb['rating'],
                'Validation Score': fb['validation_score'],
                'Feedback Length': len(fb['feedback']),
                'Feedback Preview': fb['feedback'][:100] + '...' if len(fb['feedback']) > 100 else fb['feedback']
            }
            for fb in st.session_state.feedback_history
        ])
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Rating trends
            fig = px.line(
                feedback_df,
                x='Timestamp',
                y='Rating',
                title='Performance Rating Trends',
                markers=True
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Validation score trends
            fig = px.line(
                feedback_df,
                x='Timestamp',
                y='Validation Score',
                title='Validation Score Trends',
                markers=True
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Feedback history table
        st.markdown("**ğŸ“‹ Feedback History:**")
        st.dataframe(feedback_df, use_container_width=True)
    
    # Enhanced export and documentation
    st.markdown("### ğŸ“¤ Export & Documentation")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ“‹ Generate Comprehensive Report", type="primary"):
            report = f"""
# SDG 4 AI Solution - Comprehensive Report

## Executive Summary
This report provides a detailed analysis of the SDG 4 AI solution implementation, including model performance, validation results, and recommendations for deployment.

## Model Configuration
- **Model Type:** {st.session_state.get('model_type', 'Not trained')}
- **Target Variable:** {st.session_state.get('target_variable', 'Not selected')}
- **Features Used:** {len(st.session_state.get('training_features', [])) if st.session_state.get('training_features') else 'No features'}
- **Training Date:** {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}

## Performance Metrics
{st.session_state.get('model_metrics', 'No metrics available')}

## Data Summary
- **Total Records:** {st.session_state.processed_data.shape[0] if st.session_state.processed_data is not None else 'No data'}
- **Features Analyzed:** {st.session_state.processed_data.shape[1] if st.session_state.processed_data is not None else 'No data'}
- **Data Quality:** High-quality preprocessed dataset

## Validation Results
- **Average Rating:** {np.mean([fb['rating'] for fb in st.session_state.get('feedback_history', [])]) if st.session_state.get('feedback_history') else 'No feedback'}
- **Validation Score:** {np.mean([fb['validation_score'] for fb in st.session_state.get('feedback_history', [])]) if st.session_state.get('feedback_history') else 'No validation'}
- **Total Feedback Entries:** {len(st.session_state.get('feedback_history', []))}

## Recommendations
1. **Deployment Readiness:** Model shows strong performance for SDG 4 data gap analysis
2. **Continuous Monitoring:** Implement regular model validation and retraining
3. **Stakeholder Engagement:** Gather ongoing feedback from education policy experts
4. **Data Expansion:** Consider incorporating additional data sources for enhanced accuracy

## Technical Specifications
- **Platform:** Streamlit-based low-code AI solution
- **Algorithms:** Scikit-learn machine learning models
- **Visualization:** Plotly interactive charts and dashboards
- **Deployment:** Cloud-ready with Docker containerization support

---
**Generated by:** SDG 4 AI Solution Platform
**Report Date:** {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
**Version:** 2.0 Enhanced (Fixed)
            """
            
            st.download_button(
                label="ğŸ“¥ Download Comprehensive Report",
                data=report,
                file_name=f"sdg4_comprehensive_report_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.md",
                mime="text/markdown",
                use_container_width=True
            )
    
    with col2:
        if st.button("ğŸ“Š Export Model Configuration", type="secondary"):
            config = {
                'model_type': st.session_state.get('model_type', 'Not trained'),
                'target_variable': st.session_state.get('target_variable', 'Not selected'),
                'training_features': st.session_state.get('training_features', []),
                'selected_features': st.session_state.get('selected_features', []),
                'model_metrics': st.session_state.get('model_metrics', {}),
                'feedback_summary': {
                    'total_feedback': len(st.session_state.get('feedback_history', [])),
                    'average_rating': np.mean([fb['rating'] for fb in st.session_state.get('feedback_history', [])]) if st.session_state.get('feedback_history') else 0,
                    'average_validation_score': np.mean([fb['validation_score'] for fb in st.session_state.get('feedback_history', [])]) if st.session_state.get('feedback_history') else 0
                }
            }
            
            import json
            config_json = json.dumps(config, indent=2, default=str)
            
            st.download_button(
                label="ğŸ“¥ Download Model Config (JSON)",
                data=config_json,
                file_name=f"sdg4_model_config_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                use_container_width=True
            )

# Enhanced Footer
st.markdown("---")
st.markdown("""
<div class="footer">
    <h3>ğŸ“ SDG 4 Low-Code AI Solution</h3>
    <p><strong>Bridging Education Data Gaps with Advanced Machine Learning</strong></p>
    <p>Empowering education stakeholders with accessible AI tools for sustainable development</p>
    <br>
    <p><em>Developed for quality education monitoring and policy optimization</em></p>
    <p>Version 2.0 Enhanced (Fixed) | Â© 2024 SDG AI Solutions</p>
</div>
""", unsafe_allow_html=True)

